---
layout: post
title: ceph客户端条带化
tags:
- ceph
categories: ceph
description: ceph源代码分析
---


这里我们在具体介绍ceph的客户端（RadosClient)之前，我们会先介绍一下数据的条带化(stripe)。

<!-- more -->

## 1. 什么是条带化

条带(stripe)是把连续的数据分割成大小相同的数据块，把每段数据分别写入到阵列中的不同磁盘上的方法。简单的说，条带是一种将多个磁盘驱动器合并为一个卷的方法。许多情况下，这是通过硬件控制器来完成的。

当多个进程同时访问一个磁盘时，可能会出现磁盘冲突。大多数磁盘系统都对访问次数（每秒的IO操作，IOPS）和数据传输率(每秒传输的数据量，TPS）有限制。当达到这些限制时，后面需要访问磁盘的IO请求就需要等待，这时就是所谓的磁盘冲突。避免磁盘冲突是优化IO性能的一个重要指标，而IO性能的优化与其他资源（如CPU和内存）的优化有着很大的区别，IO优化最有效的手段是将IO最大限度的进行平衡。

条带化技术就是一种自动的将IO的负载均衡到多个物理磁盘上的技术，条带化技术就是将一块连续的数据分成很多小部分并把它们分别存储到不同磁盘上去。这就能使多个进程同时访问数据的多个不同部分而不会造成磁盘冲突，而且在需要对这种数据进行顺序访问的时候可以获得最大程度上的IO并行能力，从而获得非常好的性能。由于条带化在IO性能问题上的优越表现，以至于在应用系统所在的计算环境中的多个层次或平台都涉及到了条带化技术，如操作系统和存储系统这两个层次中都可使用条带化技术。

条带化后，```条带卷```所能提供的速速比单个盘所能提供的速度要快很多。由于现在存储技术成熟，大多数系统都采用条带化来实现系统的IO负载分担，如果OS有LVM软件或者硬件条带设备，决定因数是```条带深度```(stripe depth)和```条带宽度```(stripe width)。

1） **条带深度**

条带深度指的是```条带的大小```，有时也被叫做block size，chunk size，stripe length、stripe unit或者granularity。这个参数指的是写在每块磁盘上的条带数据块的大小。RAID的数据块大小一般在2KB到512KB之间（或者更大），其数值是2的N次方，即2KB、4KB、8KB、16KB...这样。

条带大小对性能的影响比条带宽度难以量化的多：

* 减少条带大小：由于条带大小减少了，则文件被分成了更多、更小的数据块。这些数据块会被分散到更多的磁盘上存储，因此提高了传输的性能，但是由于要多次寻找不同的数据块，磁盘定位的性能就下降了。

* 增加条带大小：与减少条带大小相反，会降低传输性能，提高定位性能。


根据上边的论述，我们会发现根据不同的应用类型，不同的性能需求，不同驱动器的不同特点（如SSD硬盘），不存在一个普遍适用的```“最佳条带大小”```。所以，这也是存储厂家，文件系统编写者允许我们自己定义条带大小的原因。


2) **条带宽度**

是指可以同时并发读或写的条带数量。这个数量等于RAID中的物理硬盘数量。例如，一个经过条带化的，具有4块物理硬盘的阵列的条带宽度就是4。增加条带宽度，可以增加阵列的读写性能。道理很明显，增加更多的硬盘，也就增加了可以同时并发读或写的条带数量。在其他条件一样的前提下，一个由8块18G硬盘组成的阵列相比一个由4块36G硬盘组成的阵列具有更高的传输性能。

###### OLTP系统中的条带化
On-Line Transaction Processing联机事务处理过程(OLTP)，也称为面向交易的处理过程，其基本特征是前台接收的用户数据可以立即传送到计算中心进行处理，并在很短的时间内给出处理结果，是对用户操作快速响应的方式之一。

下面我们先来看看在```Oracle数据库```系统中影响IO大小的相关参数：

* db_block_size: oracle数据块的大小，也决定了oracle一次单个IO请求中oracle数据块的大小

* db_file_multiblock_read_count： 在多数据块读时，一次读取数据块的数量，它和参数db_block_size一起决定了一次多数据块读的大小，它们的乘积不能大于操作系统的最大IO大小

* 操作系统的数据块大小： 这个参数决定了Redo Log和Archive Log操作时的数据块大小，对于大多数Unix系统来说，该值为512KB。在Linux系统中，我们可以通过如下方式来进行查看：
{% highlight string %}
# lsblk
NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
sda      8:0    0   80G  0 disk 
├─sda1   8:1    0  300M  0 part /boot
├─sda2   8:2    0  4.9G  0 part [SWAP]
└─sda3   8:3    0 74.9G  0 part /
sr0     11:0    1 1024M  0 rom  

# fdisk -l /dev/sda3                           //方式1

Disk /dev/sda3: 80.3 GB, 80348184576 bytes, 156930048 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes

# blockdev --getbsz /dev/sda3                   //方式2
512
{% endhighlight %}

* 最大操作系统IO大小： 决定了一次单个的IO操作的IO大小的上限，对于大多数Unix系统来说，由参数max_io_size设置(注： 在Linux上貌似已经没有该参数了）

* sort_area_size: 内存中sort area的大小，也决定了并发排序操作时的IO大小

* hash_area_size: 内存中hash area的大小，也决定了哈希操作的IO大小

在OLTP系统中，会存在大量小的并发的IO请求，这时就需要考虑选择比较大的条带深度。使```条带深度```大于IO大小就称为粗粒度条带(Coarse Grain Striping)。在高度并行系统中，条带深度为(n * db_block_size)，其中n为大于1的整数。

通过粗粒度条带能实现最大的IO吞吐量（一次物理IO可以同时相应多个并发的逻辑IO）。大的条带深度能够使像全表扫描那样的多数据块读操作由一个磁盘驱动器来响应，并提高多数据块读操作的性能。

在低并发度的DSS系统中，由于IO请求比较序列化，为避免出现热点磁盘，我们需要避免逻辑IO只有一块磁盘处理。这时，粗粒度条带就不适合了。我们选择小的条带深度，使一个逻辑IO分布到多个磁盘上，从而实现IO的负载均衡。这就叫细粒度条带。条带深度的大小为(n * db_block_size)，其中n为小于多数据块读参数（db_file_multiblock_read_count）大小的整数。

注：决策支持系统（Decision Support System）是一个基于计算机用于支持业务或组织决策活动的信息系统。 DSS服务于组织管理、运营和规划管理层（通常是中级和高级管理层），并帮助人们对可能快速变化并且不容易预测结果的问题做出决策。决策支持系统可以全计算机化、人力驱动或二者结合。

通过上面我们可以简单的理解为并发程度高的IO采用粗粒度条带化，并发度低的IO采用细粒度条带化。

IO过程中，你无法保证Oracle数据块的边界能和条带单元的大小对齐。如果条带深度大小和Oracle数据块大小完全相同，而它们的边界没有对齐的话，那么就会存在大量一个单独的IO请求被两块磁盘来完成。

在OLTP系统中，为了避免一个逻辑IO请求被多个物理IO操作完成，```条带深度```就需要设置为两倍或两倍以上于Oracle数据块大小。例如，如果条带深度是IO大小的N倍，对于大量并发IO请求，我们可以保证最少有(N-1)/N的请求是由一块磁盘来完成。


## 2. ceph客户端数据的条带化
当用户使用RBD、RGW、CephFS类型客户端接口来存储数据时，会经历一个透明的、将数据转化为RADOS统一处理对象的过程，这个过程就称之为数据条带化或分片处理。

熟悉存储系统的你不会对条带化感到陌生，



<br />
<br />

**[参看]**

1. [Ceph 的物理和逻辑结构](https://www.cnblogs.com/sammyliu/p/4836014.html)

2. [小甲陪你一起看Ceph](https://cloud.tencent.com/developer/article/1428004)

3. [Ceph 分布式存储架构解析与工作原理](https://www.cnblogs.com/jmilkfan-fanguiju/p/11825073.html#_71)

4. [什么是条带化(striping) ？](https://blog.csdn.net/jlds123/article/details/11813313)

<br />
<br />
<br />

